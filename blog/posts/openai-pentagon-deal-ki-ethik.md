---
title: "OpenAI hat den Pakt mit dem Teufel geschlossen"
slug: "openai-pentagon-deal-ki-ethik"
date: "2026-02-28"
description: "Anthropic sagt Nein zum Pentagon. OpenAI unterschreibt. Was das für die Zukunft von KI bedeutet – und warum diese Weggabelung die gesamte Branche verändert."
keywords: "OpenAI Pentagon, Anthropic Militär, KI Ethik, KI autonome Waffen, KI Massenüberwachung, Department of War KI, KI Gesellschaft"
category: "Aktuelles"
---

Es gibt Momente, in denen sich entscheidet, wer eine Branche wirklich ist. Nicht auf Bühnen bei Konferenzen. Nicht in Pressemitteilungen über "verantwortungsvolle KI". Sondern dann, wenn jemand klopft und sagt: Unterschreib hier — oder du bist draußen.

Dieser Moment ist gerade eingetreten. Und die KI-Branche hat ihn versagt.

## Was passiert ist

Das US-Verteidigungsministerium — unter Kriegsminister Pete Hegseth inzwischen bezeichnenderweise wieder "Department of War" genannt — hat eine klare Ansage an alle KI-Unternehmen gemacht: Wer staatliche Verträge will, muss "any lawful use" seiner Modelle akzeptieren. Keine Ausnahmen. Keine roten Linien. Voller Zugriff.

Anthropic, das Unternehmen hinter Claude, hat genau zwei Ausnahmen gefordert:

**1. Massenüberwachung der eigenen Bevölkerung**

Der Einsatz von KI zur massenhaften Überwachung von Bürgern stellt nach Anthropics Einschätzung eine ernsthafte, neuartige Bedrohung für bürgerliche Grundrechte dar. Unvereinbar mit demokratischen Werten.

**2. Vollständig autonome Waffensysteme**

Aktuelle KI-Modelle sind nach Einschätzung von Anthropic nicht zuverlässig genug, um Waffensysteme ohne menschliche Kontrolle zu steuern. Der Einsatz würde amerikanische Soldaten und Zivilisten gefährden — nicht schützen.

Zwei Ausnahmen. Nicht zwanzig. Nicht eine Liste von Bedingungen. Zwei klare, begründete rote Linien.

Das Ergebnis: Pete Hegseth plant, Anthropic als **"Supply Chain Risk"** einzustufen — eine Bezeichnung, die bislang ausschließlich für feindliche Staaten reserviert war. Nie zuvor wurde sie öffentlich gegen ein amerikanisches Unternehmen eingesetzt. Anthropic war wohlgemerkt das erste KI-Unternehmen überhaupt, das seine Modelle in klassifizierten Netzwerken der US-Regierung einsetzte. Seit Juni 2024 arbeitet das Unternehmen mit dem Militär zusammen.

Anthropic hat angekündigt, die Einstufung gerichtlich anzufechten.

## OpenAI nimmt den Deal an

Stunden nach der Nachricht über Anthropic wurde bekannt: OpenAI hat einen Vertrag mit dem Pentagon unterzeichnet.

Keine öffentlichen roten Linien. Kein Statement zu Ausnahmen. Kein "We can't agree to this."

OpenAI — das Unternehmen, das seine Existenz mit dem Versprechen begründete, KI zum Wohl der gesamten Menschheit zu entwickeln — hat den Deal gemacht, den Anthropic ablehnte.

Das ist kein kleines Detail. Das ist eine Richtungsentscheidung, die die Branche spaltet.

## KI ist auf dem Schlachtfeld angekommen

Was gerade passiert, geht weit über einen Unternehmensstreit hinaus. Es geht um eine fundamentale Frage: Wer entscheidet, wofür KI eingesetzt wird?

KI ist längst nicht mehr nur ein Werkzeug für Unternehmensproduktivität oder einen besseren Netflix-Algorithmus. Sie ist in den Alltag der Menschen eingedrungen — und sie marschiert gerade in Richtung Schlachtfeld. Regierungen entscheiden heute, welche Modelle Teil staatlicher Machtstrukturen werden. Diese Entscheidungen werden das Kräfteverhältnis der gesamten KI-Branche langfristig prägen.

Der Wettbewerb zwischen KI-Laboren findet nicht mehr nur auf der Ebene von Benchmarks und Modellleistung statt. Er findet auf politischer und militärischer Ebene statt. Und wer sich dem Staat verweigert, riskiert nicht nur Vertragslosigkeit — sondern als Sicherheitsrisiko gebrandmarkt zu werden.

## Das Szenario, das wir hätten haben können

Stell dir mal kurz folgendes vor.

Anthropic lehnt ab. OpenAI lehnt auch ab. Google DeepMind lehnt ab. xAI lehnt ab. Alle großen KI-Labore der Welt stehen gemeinsam auf und sagen: Nein. Nicht ohne ethische Leitplanken. Nicht für Massenüberwachung. Nicht für autonome Tötungsmaschinen.

Was hätte die US-Regierung getan? Gar nichts. Denn ohne die Technologie, die diese Unternehmen entwickeln, gibt es keine KI-gestützte Militärstrategie.

Stattdessen erleben wir das Gegenteil: Einzelne Unternehmen werden durch Druck und wirtschaftliche Ausgrenzung zermürbt, während andere die entstandene Lücke füllen. Das System des "Divide and Conquer" funktioniert — weil die Branche keine gemeinsame Linie hat.

Anthropic zeigt, dass es möglich ist, Haltung zu bewahren. Dass man "Nein" sagen kann, auch wenn es teuer wird. Das verdient Respekt.

Aber ein einzelnes Nein reicht nicht, wenn alle anderen Ja sagen.

## Was das für uns bedeutet

Wir sind in einer Phase, in der die gesellschaftliche Debatte über KI noch weitgehend auf Produktivität, Automatisierung und Jobverlust fokussiert ist. Die eigentlich entscheidenden Fragen — Wer kontrolliert KI? Für welche Zwecke wird sie eingesetzt? Wo sind die nicht verhandelbare Grenzen? — diese Fragen werden gerade hinter verschlossenen Türen beantwortet.

Was jetzt passiert, wird nicht rückgängig zu machen sein. Wenn autonome Waffensysteme einmal auf KI-Modellen basieren, die "any lawful use" akzeptieren, dann ist die Büchse offen. Dann folgt der nächste Staat. Und der übernächste.

Anthropic hat eine Grenze gezogen. Die Frage ist: Wer zieht die nächste?

---

*Das ist ein Meinungsbeitrag. Die zitierten Aussagen von Anthropic stammen aus der offiziellen Stellungnahme des Unternehmens.*
